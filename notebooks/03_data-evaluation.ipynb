{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ffd49a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "daea66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "from churn.utils import set_seed\n",
    "from churn.eval import evaluate_model, set_eval_theme, get_feature_importance\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "set_eval_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b409f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = r\"C:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\models\"\n",
    "VAL_CSV = r\"C:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\data\\processed\\val_processed.csv\"\n",
    "TEST_CSV = r\"C:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\data\\processed\\test_processed.csv\"\n",
    "TARGET = \"CHURN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b4b7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(VAL_CSV)\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "\n",
    "X_val, y_val = val_df.drop(columns=[\"CHURN\"]), val_df[TARGET].astype(int)\n",
    "X_test, y_test = test_df.drop(columns=[\"CHURN\"]), test_df[TARGET].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5a049",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\path\\to\\logistic_regression_model.joblib\"\n",
    "res_lr = evaluate_model(model_path, X_val, y_val, X_test, y_test, threshold=\"f1\")\n",
    "\n",
    "print(f\"Threshold: {res_lr['threshold']:.3f}\\n\")\n",
    "print(\"Validation Metrics:\")\n",
    "for k, v in res_lr[\"val_metrics\"].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k:>12}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for k, v in res_lr[\"test_metrics\"].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k:>12}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n--- Classification Report (Validation) ---\")\n",
    "print(res_lr[\"val_report\"])\n",
    "\n",
    "print(\"\\n--- Classification Report (Test) ---\")\n",
    "print(res_lr[\"test_report\"])\n",
    "\n",
    "if res_lr[\"importances\"] is not None:\n",
    "    imp_lr = get_feature_importance(res_lr[\"model\"], res_lr[\"features\"], plot=True, top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a54981",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff9b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\models\\random_forest_model.joblib\"\n",
    "res_rf = evaluate_model(model_path, X_val, y_val, X_test, y_test, threshold=\"f1\")\n",
    "\n",
    "print(f\"Threshold: {res_rf['threshold']:.3f}\\n\")\n",
    "print(\"Validation Metrics:\")\n",
    "for k, v in res_rf[\"val_metrics\"].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k:>12}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for k, v in res_rf[\"test_metrics\"].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k:>12}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n--- Classification Report (Validation) ---\")\n",
    "print(res_rf[\"val_report\"])\n",
    "\n",
    "print(\"\\n--- Classification Report (Test) ---\")\n",
    "print(res_rf[\"test_report\"])\n",
    "\n",
    "# feature importance graph\n",
    "if res_rf[\"importances\"] is not None:\n",
    "    imp_rf = get_feature_importance(res_rf[\"model\"], res_rf[\"features\"], plot=True, top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8110140",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7dae0063",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muni\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAI7101-Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mxgboost_model.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m res_gb \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThreshold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres_gb[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\src\\churn\\eval.py:179\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model_path, X_val, y_val, X_test, y_test, threshold)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model_path: \u001b[38;5;28mstr\u001b[39m, \n\u001b[0;32m    175\u001b[0m                   X_val: pd\u001b[38;5;241m.\u001b[39mDataFrame, y_val: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[0;32m    176\u001b[0m                   X_test: pd\u001b[38;5;241m.\u001b[39mDataFrame, y_test: pd\u001b[38;5;241m.\u001b[39mSeries,\n\u001b[0;32m    177\u001b[0m                   threshold: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 179\u001b[0m     model, features \u001b[38;5;241m=\u001b[39m \u001b[43mload_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine feature names. Save model with features.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\src\\churn\\eval.py:29\u001b[0m, in \u001b[0;36mload_artifact\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_artifact\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 29\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     32\u001b[0m         model \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\.conda\\envs\\pythonProject\\Lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\PC\\.conda\\envs\\pythonProject\\Lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\.conda\\envs\\pythonProject\\Lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\Users\\PC\\.conda\\envs\\pythonProject\\Lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\PC\\.conda\\envs\\pythonProject\\Lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[38;5;28m__import__\u001b[39m(module, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "model_path = r\"C:\\Users\\PC\\OneDrive\\Documents\\uni\\AI7101-Project\\models\\xgboost_model.joblib\"\n",
    "res_gb = evaluate_model(model_path, X_val, y_val, X_test, y_test, threshold=\"f1\")\n",
    "\n",
    "print(f\"Threshold: {res_gb['threshold']:.3f}\\n\")\n",
    "print(\"Validation Metrics:\")\n",
    "for k, v in res_gb[\"val_metrics\"].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k:>12}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for k, v in res_gb[\"test_metrics\"].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"  {k:>12}: {v:.4f}\")\n",
    "\n",
    "print(\"\\n--- Classification Report (Validation) ---\")\n",
    "print(res_gb[\"val_report\"])\n",
    "\n",
    "print(\"\\n--- Classification Report (Test) ---\")\n",
    "print(res_gb[\"test_report\"])\n",
    "\n",
    "# Feature importance\n",
    "if res_gb[\"importances\"] is not None:\n",
    "    imp_gb = get_feature_importance(res_gb[\"model\"], res_gb[\"features\"], plot=True, top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69468f2",
   "metadata": {},
   "source": [
    "## Final Comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e214da7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m all_results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogistic Regression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mres_lr\u001b[49m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m: res_rf,\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient Boosting\u001b[39m\u001b[38;5;124m\"\u001b[39m: res_gb\n\u001b[0;32m      5\u001b[0m }\n\u001b[0;32m      7\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, res \u001b[38;5;129;01min\u001b[39;00m all_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res_lr' is not defined"
     ]
    }
   ],
   "source": [
    "all_results = {\n",
    "    \"Logistic Regression\": res_lr,\n",
    "    \"Random Forest\": res_rf,\n",
    "    \"Gradient Boosting\": res_gb\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, res in all_results.items():\n",
    "    vm = res[\"val_metrics\"]\n",
    "    tm = res[\"test_metrics\"]\n",
    "    rows.append({\n",
    "        \"Model\": name,\n",
    "        \"Val ROC AUC\": vm[\"roc_auc\"],\n",
    "        \"Test ROC AUC\": tm[\"roc_auc\"],\n",
    "        \"Val PR AUC\": vm[\"pr_auc\"],\n",
    "        \"Test PR AUC\": tm[\"pr_auc\"],\n",
    "        \"Val F1\": vm[\"f1\"],\n",
    "        \"Test F1\": tm[\"f1\"],\n",
    "        \"Threshold\": res[\"threshold\"],\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(rows).sort_values(\"Test ROC AUC\", ascending=False)\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b365ff",
   "metadata": {},
   "source": [
    "## Save Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a31bffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figures saved to: ..\\figs\n"
     ]
    }
   ],
   "source": [
    "outdir = r\"..\\figs\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "for name, res in all_results.items():\n",
    "    for tag, fig in res[\"figures\"].items():\n",
    "        fig.savefig(os.path.join(outdir, f\"{name.replace(' ','_')}_{tag}.png\"))\n",
    "\n",
    "print(f\"Figures saved to: {outdir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
